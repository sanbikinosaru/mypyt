{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binance1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKD35ShmjBw6RFcWM2+7Qb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgeCxo1zTaWD",
        "outputId": "c6ff2983-c331-4593-bec2-622f135b7d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting binance-connector\n",
            "  Downloading binance_connector-1.13.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting ta\n",
            "  Downloading ta-0.10.1.tar.gz (24 kB)\n",
            "Collecting autobahn>=21.2.1\n",
            "  Downloading autobahn-22.5.1.tar.gz (435 kB)\n",
            "\u001b[K     |████████████████████████████████| 435 kB 11.2 MB/s \n",
            "\u001b[?25hCollecting Twisted>=21.2.0\n",
            "  Downloading Twisted-22.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 40.2 MB/s \n",
            "\u001b[?25hCollecting requests>=2.25.1\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=19.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting service-identity>=21.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting txaio>=21.2.1\n",
            "  Downloading txaio-22.2.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting cryptography>=3.4.6\n",
            "  Downloading cryptography-37.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 33.9 MB/s \n",
            "\u001b[?25hCollecting hyperlink>=21.0.0\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from autobahn>=21.2.1->binance-connector) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.6->autobahn>=21.2.1->binance-connector) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.6->autobahn>=21.2.1->binance-connector) (2.21)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=21.0.0->autobahn>=21.2.1->binance-connector) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->binance-connector) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->binance-connector) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->binance-connector) (2.0.12)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=21.1.0->binance-connector) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=21.1.0->binance-connector) (0.2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from service-identity>=21.1.0->binance-connector) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=21.1.0->binance-connector) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=21.2.0->binance-connector) (4.1.1)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting zope.interface>=4.4.2\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2022.1)\n",
            "Building wheels for collected packages: autobahn, ta\n",
            "  Building wheel for autobahn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autobahn: filename=autobahn-22.5.1-cp37-cp37m-linux_x86_64.whl size=635258 sha256=69031f2754e3d6ecf74a9472a3591afac324b25cda200c90d96435779f1e0c9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/3d/10/4af119dc09a42cb9bb3bb96cdfc0af08ede92dabafe366afbb\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.10.1-py3-none-any.whl size=28985 sha256=b1513a0eefb6036b147baed388efa1a92419ec89925e050406564d771059986d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/2a/c2/a56e77d07edc16a1fa7fb012667e55cb0643cfa65996bddecc\n",
            "Successfully built autobahn ta\n",
            "Installing collected packages: zope.interface, txaio, incremental, hyperlink, cryptography, constantly, Automat, Twisted, service-identity, requests, pyOpenSSL, autobahn, ta, binance-connector\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Automat-20.2.0 Twisted-22.4.0 autobahn-22.5.1 binance-connector-1.13.0 constantly-15.1.0 cryptography-37.0.3 hyperlink-21.0.0 incremental-21.3.0 pyOpenSSL-22.0.0 requests-2.28.0 service-identity-21.1.0 ta-0.10.1 txaio-22.2.1 zope.interface-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install binance-connector ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Version 2.0 - download from first to last\n",
        "#  !pip install binance-connector ta\n",
        "from typing import *\n",
        "from binance.spot import Spot as Client\n",
        "import datetime as datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "def ms_to_dt(ms: int) -> datetime.datetime:\n",
        "    return datetime.datetime.utcfromtimestamp(ms / 1000)\n",
        "\n",
        "client = Client()\n",
        "server_time = client.time()\n",
        "print(ms_to_dt(server_time['serverTime']))\n",
        "end_time = server_time['serverTime'] - 61000\n",
        "print(ms_to_dt(end_time))\n",
        "\n",
        "\n",
        "def data_tocsv(candles, my_symbol):\n",
        "    path = 'binance_csvs2/'\n",
        "    df = pd.DataFrame(candles)\n",
        "    df.to_csv(path+my_symbol+'.csv', mode = 'a', header = False, index=False)\n",
        "\n",
        "\n",
        "def read_csv(my_symbol):\n",
        "    path = 'binance_csvs2/'\n",
        "    dt = pd.read_csv(path+my_symbol+'.csv', names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l'])\n",
        "    dt['z'] = pd.to_datetime(dt['a'], unit='ms')\n",
        "    # dt = dt.set_index('a')\n",
        "    # print(\"Reading db...\")\n",
        "    # print(dt.tail(5))\n",
        "    return dt\n",
        "\n",
        "\n",
        "def get_first_last_timestamp(my_symbol: str) -> Union[Tuple[None, None], Tuple[float, float]]:\n",
        "    print(\"Scanning Timestamp of older Data\")\n",
        "    existing_data = read_csv(my_symbol)\n",
        "    \n",
        "    if len(existing_data) == 0:\n",
        "        return None, None\n",
        "\n",
        "    first_ts = min(existing_data['a'])\n",
        "    last_ts = max(existing_data['a'])\n",
        "    print(\"LAST_TS in db found\", ms_to_dt(last_ts))\n",
        "    \n",
        "    return first_ts, last_ts\n",
        "\n",
        "def collect_all(my_symbol):\n",
        "    client = Client()\n",
        "    path = 'binance_csvs2/'\n",
        "    if os.path.isfile(path+my_symbol+'.csv'):\n",
        "        oldest_ts, most_recent_ts = get_first_last_timestamp(my_symbol)\n",
        "        next_todownload_ts = most_recent_ts + 1\n",
        "    else:\n",
        "        # Initial Request\n",
        "        os.makedirs(path)\n",
        "        kline_data = client.klines(symbol=my_symbol, interval='1m', startTime=0,  endTime=end_time, limit=1000)\n",
        "        print(my_symbol, \": Collected\", len(kline_data),\"older data from\",  \n",
        "                    ms_to_dt(kline_data[0][0]), \"to\" , ms_to_dt(kline_data[-1][0]))\n",
        "        data_tocsv(kline_data, my_symbol)\n",
        "        # oldest_ts = kline_data[0][0]\n",
        "        most_recent_ts = kline_data[-1][0]\n",
        "        next_todownload_ts = most_recent_ts + 1\n",
        "        \n",
        "    data_to_insert = []\n",
        "    \n",
        "    while True:\n",
        "            kline_data = client.klines(symbol=my_symbol, interval='1m', startTime=next_todownload_ts, endTime=end_time, limit=1000)\n",
        "\n",
        "            if kline_data is None:\n",
        "                time.sleep(3)  # Pause in case an error occurs during the request\n",
        "                continue\n",
        "\n",
        "            if len(kline_data) == 0:\n",
        "                print(my_symbol, \": Stopped. No more available latest kline data from \",\n",
        "                            ms_to_dt(most_recent_ts))\n",
        "                break\n",
        "\n",
        "            most_recent_ts = kline_data[-1][0]\n",
        "            next_todownload_ts = most_recent_ts + 1\n",
        "\n",
        "            print(my_symbol, \": Collected\", len(kline_data),\"older data from\",  \n",
        "                        ms_to_dt(kline_data[0][0]), \"to\" , ms_to_dt(most_recent_ts))\n",
        "        \n",
        "\n",
        "            data_to_insert = data_to_insert + kline_data\n",
        "\n",
        "            if len(data_to_insert) >= 50000:\n",
        "                data_tocsv(data_to_insert, my_symbol)\n",
        "                print(\"Saving older Data to DISK\")\n",
        "                print(len(data_to_insert))\n",
        "                data_to_insert.clear()\n",
        "      \n",
        "    data_tocsv(data_to_insert, my_symbol)\n",
        "    print(\"Saving Data to DISK\")\n",
        "    print(len(data_to_insert))\n",
        "    data_to_insert.clear()\n",
        "\n",
        "\n",
        "relevant = ['BTCUSDT']\n",
        "\n",
        "for list in relevant:\n",
        "    print(\"Downloading\", list, \"data\")\n",
        "    collect_all(list)\n",
        "\n",
        "# [\n",
        "#   [\n",
        "#     1499040000000,      // Open time\n",
        "#     \"0.01634790\",       // Open\n",
        "#     \"0.80000000\",       // High\n",
        "#     \"0.01575800\",       // Low\n",
        "#     \"0.01577100\",       // Close\n",
        "#     \"148976.11427815\",  // Volume\n",
        "#     1499644799999,      // Close time\n",
        "#     \"2434.19055334\",    // Quote asset volume\n",
        "#     308,                // Number of trades\n",
        "#     \"1756.87402397\",    // Taker buy base asset volume\n",
        "#     \"28.46694368\",      // Taker buy quote asset volume\n",
        "#     \"17928899.62484339\" // Ignore.\n",
        "#   ]\n",
        "# ]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "TO-EL-s-TfBl",
        "outputId": "4116b6cc-d651-4e9f-d465-c4bca69b6bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d79b3084292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#  !pip install binance-connector ta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbinance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'binance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import ta\n",
        "\n",
        "path = 'binance_csvs2/'\n",
        "my_symbol = 'BTCUSDT'\n",
        "dt = pd.read_csv(path+my_symbol+'.csv', names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l'])\n",
        "columns = ['a', 'b', 'c', 'd', 'e', 'f', 'h', 'i']\n",
        "df1 = pd.DataFrame(dt, columns=columns)\n",
        "df1.columns = ['date_time', 'open', 'high', 'low', 'close', 'volume', 'vol_price', 'trades']\n",
        "df1['date_time'] = pd.to_datetime(df1['date_time'], unit='ms')\n",
        "df1.set_index('date_time', drop=True, inplace=True)\n",
        "\n",
        "def checkcross(dframe):\n",
        "  series = dframe['strsi_k'] > dframe['strsi_d']\n",
        "  return series.diff()\n",
        "\n",
        "\n",
        "# df1['strsi_k'] = ta.momentum.stochrsi_k(df1.close)\n",
        "# df1['strsi_d'] = ta.momentum.stochrsi_d(df1.close)\n",
        "# for i in (8,14,50):\n",
        "#   df1['EMA_'+str(i)] = ta.trend.ema_indicator(df1.close, window=i)\n",
        "# df1['atr'] = ta.volatility.average_true_range(df1.high, df1.low, df1.close)\n",
        "# df1.dropna(inplace=True)\n",
        "# df1['cross'] = checkcross(df1)\n",
        "# df1['TP'] = df1.close + (df1.atr * 5)\n",
        "# df1['SL'] = df1.close - (df1.atr * 3)\n",
        "# df1['Buysignal'] = np.where((df1.cross) & (df1.close > df1.EMA_8) & (df1.EMA_8 > df1.EMA_14) & (df1.EMA_14 > df1.EMA_50) ,1 , 0)\n",
        "\n",
        "# resampling tha data function\n",
        "\n",
        "TF_EQUIV = {\"1m\": \"1Min\", \"5m\": \"5Min\", \"15m\": \"15Min\", \"30m\": \"30Min\", \"1h\": \"1H\", \"4h\": \"4H\", \"12h\": \"12H\", \"1d\": \"D\"}\n",
        "\n",
        "def resample_timeframe(data: pd.DataFrame, tf: str) -> pd.DataFrame:\n",
        "    return data.resample(TF_EQUIV[tf]).agg(\n",
        "        {\"open\": \"first\", \"high\": \"max\", \"low\": \"min\", \"close\": \"last\", \"volume\": \"sum\" , \"vol_price\": \"sum\", \"trades\": \"sum\"})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1ljzbMBTnZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df5 = resample_timeframe(df1,'5m')\n",
        "\n",
        "df5['strsi_k'] = ta.momentum.stochrsi_k(df5.close)\n",
        "df5['strsi_d'] = ta.momentum.stochrsi_d(df5.close)\n",
        "\n",
        "for i in (8,14,50):\n",
        "  df5['EMA_'+str(i)] = ta.trend.ema_indicator(df5.close, window=i)\n",
        "\n",
        "df5['atr'] = ta.volatility.average_true_range(df5.high, df5.low, df5.close)\n",
        "df5.dropna(inplace=True)\n",
        "\n",
        "df5['cross'] = checkcross(df5)\n",
        "df5['TP'] = df5.close + (df5.atr * 2)\n",
        "df5['SL'] = df5.close - (df5.atr * 1)\n",
        "df5['Buysignal'] = np.where((df5.cross) & (df5.close > df5.EMA_8) & (df5.EMA_8 > df5.EMA_14) & (df5.EMA_14 > df5.EMA_50) ,1 , 0)\n",
        "\n",
        "# Get sell dates\n",
        "selldates = []\n",
        "outcome = []\n",
        "\n",
        "for i in range(len(df5)):\n",
        "  if df5.Buysignal.iloc[i] == 1 :\n",
        "    k = 1\n",
        "    SL = df5.SL.iloc[i]\n",
        "    TP = df5.TP.iloc[i]\n",
        "    print(SL, ' ' ,TP)\n",
        "    in_position = True\n",
        "    while in_position and  i+k < len(df5):\n",
        "      print(i+k)\n",
        "      looping_close = df5.close.iloc[i+k]\n",
        "      print(looping_close)\n",
        "      if looping_close >= TP:\n",
        "        selldates.append(df5.iloc[i+k].name)\n",
        "        outcome.append('TP')\n",
        "        in_position = False\n",
        "      elif looping_close <= SL:\n",
        "        selldates.append(df5.iloc[i+k].name)\n",
        "        outcome.append('SL')\n",
        "        in_position = False\n",
        "      k +=1\n",
        "\n",
        "df5.loc[selldates, 'Sellsignal']  = 1\n",
        "df5.loc[selldates, 'Outcome'] = outcome\n",
        "df5.Sellsignal = df5.Sellsignal.fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "gd3cZ2T-UPva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df5[(df5.Buysignal == 1) | (df5.Sellsignal == 1)]\n",
        "df5 = df5[(df5.Buysignal.diff() == 1) | (df5.Sellsignal.diff() == 1)]"
      ],
      "metadata": {
        "id": "B1xYLjqoUfnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5.Outcome.value_counts()"
      ],
      "metadata": {
        "id": "Df1m46AfUg7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}